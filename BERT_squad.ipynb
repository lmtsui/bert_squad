{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/huggingface/transformers/blob/master/examples/run_squad.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "colab_type": "code",
    "id": "Bn_B25-GTFBt",
    "outputId": "6a3a2dec-ead9-46fa-8d4f-5d1a96c06584"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 4.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 63.8MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
      "\u001b[K     |████████████████████████████████| 870kB 59.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.47)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.47)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (2.6.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (0.15.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=38c0fbf8d8dba7f48f4e53b46a1670b4d6b60e6a416acfb11f0590ae22ac66c9\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sentencepiece, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 transformers-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 671
    },
    "colab_type": "code",
    "id": "JWRlNmsfRs0m",
    "outputId": "57c263b4-17bc-4ffd-9d71-b1ff7037b67c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-01-14 20:55:22--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
      "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.110.153, 185.199.111.153, 185.199.108.153, ...\n",
      "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.110.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 30288272 (29M) [application/json]\n",
      "Saving to: ‘train-v1.1.json’\n",
      "\n",
      "train-v1.1.json     100%[===================>]  28.88M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2020-01-14 20:55:22 (226 MB/s) - ‘train-v1.1.json’ saved [30288272/30288272]\n",
      "\n",
      "--2020-01-14 20:55:22--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n",
      "Reusing existing connection to rajpurkar.github.io:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4854279 (4.6M) [application/json]\n",
      "Saving to: ‘dev-v1.1.json’\n",
      "\n",
      "dev-v1.1.json       100%[===================>]   4.63M  --.-KB/s    in 0.01s   \n",
      "\n",
      "2020-01-14 20:55:22 (357 MB/s) - ‘dev-v1.1.json’ saved [4854279/4854279]\n",
      "\n",
      "--2020-01-14 20:55:22--  https://rawcdn.githack.com/allenai/bi-att-flow/49004549e9a88b78c359b31481afa7792dbb3f4a/squad/evaluate-v1.1.py\n",
      "Resolving rawcdn.githack.com (rawcdn.githack.com)... 172.64.108.8, 172.64.109.8, 2606:4700:e0::ac40:6d08, ...\n",
      "Connecting to rawcdn.githack.com (rawcdn.githack.com)|172.64.108.8|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/plain]\n",
      "Saving to: ‘evaluate-v1.1.py’\n",
      "\n",
      "evaluate-v1.1.py        [ <=>                ]   3.34K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-01-14 20:55:23 (62.2 MB/s) - ‘evaluate-v1.1.py’ saved [3419]\n",
      "\n",
      "FINISHED --2020-01-14 20:55:23--\n",
      "Total wall clock time: 1.1s\n",
      "Downloaded: 3 files, 34M in 0.1s (238 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json https://rawcdn.githack.com/allenai/bi-att-flow/49004549e9a88b78c359b31481afa7792dbb3f4a/squad/evaluate-v1.1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-B1QgkWicBE_"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import timeit\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "# from tqdm import tqdm, trange\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from transformers import (\n",
    "    WEIGHTS_NAME,\n",
    "    AdamW,\n",
    "    BertConfig,\n",
    "    BertForQuestionAnswering,\n",
    "    BertTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    squad_convert_examples_to_features,\n",
    ")\n",
    "\n",
    "from transformers.data.metrics.squad_metrics import (\n",
    "    compute_predictions_log_probs,\n",
    "    compute_predictions_logits,\n",
    "    squad_evaluate,\n",
    ")\n",
    "from transformers.data.processors.squad import SquadResult, SquadV1Processor, SquadV2Processor\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F81geyp3ZoWa"
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "ALL_MODELS = sum(\n",
    "    (tuple(conf.pretrained_config_archive_map.keys()) for conf in (BertConfig,)),\n",
    "    (),\n",
    ")\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    \"bert\": (BertConfig, BertForQuestionAnswering, BertTokenizer)\n",
    "}\n",
    "\n",
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "\n",
    "def to_list(tensor):\n",
    "    return tensor.detach().cpu().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wdIQ2XIUSNIL"
   },
   "outputs": [],
   "source": [
    "def train(args, train_dataset, model, tokenizer):\n",
    "    \"\"\" Train the model \"\"\"\n",
    "    tb_writer = SummaryWriter()\n",
    "\n",
    "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n",
    "\n",
    "    if args.max_steps > 0:\n",
    "        t_total = args.max_steps\n",
    "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
    "    else:\n",
    "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "\n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": args.weight_decay,\n",
    "        },\n",
    "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
    "    )\n",
    "\n",
    "    # Check if saved optimizer or scheduler states exist\n",
    "    if os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\")) and os.path.isfile(\n",
    "        os.path.join(args.model_name_or_path, \"scheduler.pt\")\n",
    "    ):\n",
    "        # Load in optimizer and scheduler states\n",
    "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
    "        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n",
    "\n",
    "    # Train!\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
    "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
    "    logger.info(\n",
    "        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
    "        args.train_batch_size\n",
    "        * args.gradient_accumulation_steps\n",
    "        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n",
    "    )\n",
    "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
    "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "    global_step = 1\n",
    "    epochs_trained = 0\n",
    "    steps_trained_in_current_epoch = 0\n",
    "    # Check if continuing training from a checkpoint\n",
    "    if os.path.exists(args.model_name_or_path):\n",
    "        try:\n",
    "            # set global_step to gobal_step of last saved checkpoint from model path\n",
    "            checkpoint_suffix = args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0]\n",
    "            global_step = int(checkpoint_suffix)\n",
    "            epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n",
    "            steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n",
    "\n",
    "            logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
    "            logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n",
    "            logger.info(\"  Continuing training from global step %d\", global_step)\n",
    "            logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n",
    "        except ValueError:\n",
    "            logger.info(\"  Starting fine-tuning.\")\n",
    "\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(\n",
    "        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=False\n",
    "    )\n",
    "    # Added here for reproductibility\n",
    "    set_seed(args)\n",
    "\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=False)\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "\n",
    "            # Skip past any already trained steps if resuming training\n",
    "            if steps_trained_in_current_epoch > 0:\n",
    "                steps_trained_in_current_epoch -= 1\n",
    "                continue\n",
    "\n",
    "            model.train()\n",
    "            batch = tuple(t.to(args.device) for t in batch)\n",
    "\n",
    "            inputs = {\n",
    "                \"input_ids\": batch[0],\n",
    "                \"attention_mask\": batch[1],\n",
    "                \"token_type_ids\": batch[2],\n",
    "                \"start_positions\": batch[3],\n",
    "                \"end_positions\": batch[4],\n",
    "            }\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            # model outputs are always tuple in transformers (see doc)\n",
    "            loss = outputs[0]\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "\n",
    "                optimizer.step()\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "                # Log metrics\n",
    "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
    "                    # Only evaluate when single GPU otherwise metrics may not average well\n",
    "                    if args.local_rank == -1 and args.evaluate_during_training:\n",
    "                        results = evaluate(args, model, tokenizer)\n",
    "                        for key, value in results.items():\n",
    "                            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n",
    "                    tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n",
    "                    tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)\n",
    "                    logging_loss = tr_loss\n",
    "\n",
    "                # Save model checkpoint\n",
    "                if  args.save_steps > 0 and global_step % args.save_steps == 0:\n",
    "                    output_dir = os.path.join(args.output_dir, \"checkpoint-{}\".format(global_step))\n",
    "                    if not os.path.exists(output_dir):\n",
    "                        os.makedirs(output_dir)\n",
    "                    # Take care of distributed/parallel training\n",
    "                    model_to_save = model.module if hasattr(model, \"module\") else model\n",
    "                    model_to_save.save_pretrained(output_dir)\n",
    "                    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "                    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
    "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "\n",
    "                    torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
    "                    torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
    "                    logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n",
    "\n",
    "            if args.max_steps > 0 and global_step > args.max_steps:\n",
    "                epoch_iterator.close()\n",
    "                break\n",
    "        if args.max_steps > 0 and global_step > args.max_steps:\n",
    "            train_iterator.close()\n",
    "            break\n",
    "\n",
    "    tb_writer.close()\n",
    "\n",
    "    return global_step, tr_loss / global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOXDvcgpi6YV"
   },
   "outputs": [],
   "source": [
    "def evaluate(args, model, tokenizer, prefix=\"\"):\n",
    "    dataset, examples, features = load_and_cache_examples(args, tokenizer, evaluate=True, output_examples=True)\n",
    "\n",
    "    if not os.path.exists(args.output_dir):\n",
    "        os.makedirs(args.output_dir)\n",
    "\n",
    "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
    "\n",
    "    # Note that DistributedSampler samples randomly\n",
    "    eval_sampler = SequentialSampler(dataset)\n",
    "    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "    logger.info(\"  Num examples = %d\", len(dataset))\n",
    "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "\n",
    "    all_results = []\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(args.device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {\n",
    "                \"input_ids\": batch[0],\n",
    "                \"attention_mask\": batch[1],\n",
    "                \"token_type_ids\": batch[2],\n",
    "            }\n",
    "\n",
    "            example_indices = batch[3]\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        for i, example_index in enumerate(example_indices):\n",
    "            eval_feature = features[example_index.item()]\n",
    "            unique_id = int(eval_feature.unique_id)\n",
    "\n",
    "            output = [to_list(output[i]) for output in outputs]\n",
    "\n",
    "            # Some models (XLNet, XLM) use 5 arguments for their predictions, while the other \"simpler\"\n",
    "            # models only use two.\n",
    "            if len(output) >= 5:\n",
    "                start_logits = output[0]\n",
    "                start_top_index = output[1]\n",
    "                end_logits = output[2]\n",
    "                end_top_index = output[3]\n",
    "                cls_logits = output[4]\n",
    "\n",
    "                result = SquadResult(\n",
    "                    unique_id,\n",
    "                    start_logits,\n",
    "                    end_logits,\n",
    "                    start_top_index=start_top_index,\n",
    "                    end_top_index=end_top_index,\n",
    "                    cls_logits=cls_logits,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                start_logits, end_logits = output\n",
    "                result = SquadResult(unique_id, start_logits, end_logits)\n",
    "\n",
    "            all_results.append(result)\n",
    "\n",
    "    evalTime = timeit.default_timer() - start_time\n",
    "    logger.info(\"  Evaluation done in total %f secs (%f sec per example)\", evalTime, evalTime / len(dataset))\n",
    "\n",
    "    # Compute predictions\n",
    "    output_prediction_file = os.path.join(args.output_dir, \"predictions_{}.json\".format(prefix))\n",
    "    output_nbest_file = os.path.join(args.output_dir, \"nbest_predictions_{}.json\".format(prefix))\n",
    "\n",
    "    output_null_log_odds_file = None\n",
    "\n",
    "    predictions = compute_predictions_logits(\n",
    "        examples,\n",
    "        features,\n",
    "        all_results,\n",
    "        args.n_best_size,\n",
    "        args.max_answer_length,\n",
    "        args.do_lower_case,\n",
    "        output_prediction_file,\n",
    "        output_nbest_file,\n",
    "        output_null_log_odds_file,\n",
    "        args.verbose_logging,\n",
    "        args.version_2_with_negative,\n",
    "        args.null_score_diff_threshold\n",
    "    )\n",
    "\n",
    "    # Compute the F1 and exact scores.\n",
    "    results = squad_evaluate(examples, predictions)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAQaXoZki79a"
   },
   "outputs": [],
   "source": [
    "def load_and_cache_examples(args, tokenizer, evaluate=False, output_examples=False):\n",
    "    # Load data features from cache or dataset file\n",
    "    input_dir = args.data_dir if args.data_dir else \".\"\n",
    "    cached_features_file = os.path.join(\n",
    "        input_dir,\n",
    "        \"cached_{}_{}_{}\".format(\n",
    "            \"dev\" if evaluate else \"train\",\n",
    "            list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n",
    "            str(args.max_seq_length),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Init features and dataset from cache if it exists\n",
    "    if os.path.exists(cached_features_file) and not args.overwrite_cache:\n",
    "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
    "        features_and_dataset = torch.load(cached_features_file)\n",
    "        features, dataset, examples = (\n",
    "            features_and_dataset[\"features\"],\n",
    "            features_and_dataset[\"dataset\"],\n",
    "            features_and_dataset[\"examples\"],\n",
    "        )\n",
    "    else:\n",
    "        logger.info(\"Creating features from dataset file at %s\", input_dir)\n",
    "\n",
    "        if not args.data_dir and ((evaluate and not args.predict_file) or (not evaluate and not args.train_file)):\n",
    "            try:\n",
    "                import tensorflow_datasets as tfds\n",
    "            except ImportError:\n",
    "                raise ImportError(\"If not data_dir is specified, tensorflow_datasets needs to be installed.\")\n",
    "\n",
    "\n",
    "            tfds_examples = tfds.load(\"squad\")\n",
    "            examples = SquadV1Processor().get_examples_from_dataset(tfds_examples, evaluate=evaluate)\n",
    "        else:\n",
    "            processor = SquadV2Processor() if args.version_2_with_negative else SquadV1Processor()\n",
    "            if evaluate:\n",
    "                examples = processor.get_dev_examples(args.data_dir, filename=args.predict_file)\n",
    "            else:\n",
    "                examples = processor.get_train_examples(args.data_dir, filename=args.train_file)\n",
    "\n",
    "        features, dataset = squad_convert_examples_to_features(\n",
    "            examples=examples,\n",
    "            tokenizer=tokenizer,\n",
    "            max_seq_length=args.max_seq_length,\n",
    "            doc_stride=args.doc_stride,\n",
    "            max_query_length=args.max_query_length,\n",
    "            is_training=not evaluate,\n",
    "            return_dataset=\"pt\",\n",
    "            # threads=args.threads,\n",
    "        )\n",
    "\n",
    "        logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
    "        torch.save({\"features\": features, \"dataset\": dataset, \"examples\": examples}, cached_features_file)\n",
    "\n",
    "    if output_examples:\n",
    "        return dataset, examples, features\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TFW398vzmHAN"
   },
   "outputs": [],
   "source": [
    "class Args():\n",
    "    model_type = 'bert'\n",
    "    model_name_or_path = 'bert-base-cased'\n",
    "    output_dir = 'tmp/debug_squad/'\n",
    "    data_dir = None\n",
    "    train_file = 'train-v1.1.json'\n",
    "    predict_file = 'dev-v1.1.json'\n",
    "    config_name = ''\n",
    "    tokenizer_name = ''\n",
    "    cache_dir = ''\n",
    "    version_2_with_negative = False\n",
    "    null_score_diff_threshold = 0.0\n",
    "    max_seq_length = 384\n",
    "    doc_stride = 128\n",
    "    max_query_length = 64\n",
    "    do_train = True\n",
    "    do_eval = True\n",
    "    evaluate_during_training = False\n",
    "    do_lower_case = True\n",
    "    per_gpu_train_batch_size = 12\n",
    "    per_gpu_eval_batch_size = 8\n",
    "    learning_rate = 3e-5\n",
    "    gradient_accumulation_steps = 1\n",
    "    weight_decay = 0.0\n",
    "    adam_epsilon = 1e-8\n",
    "    max_grad_norm = 1.0\n",
    "    num_train_epochs = 2.0\n",
    "    max_steps = -1\n",
    "    warmup_steps = 0\n",
    "    n_best_size = 20\n",
    "    max_answer_length = 30\n",
    "    verbose_logging = False\n",
    "    logging_steps = 50\n",
    "    save_steps = 1000\n",
    "    eval_all_checkpoints = False\n",
    "    no_cuda = False\n",
    "    overwrite_output_dir = False\n",
    "    overwrite_cache = False\n",
    "    seed = 42\n",
    "    local_rank = -1\n",
    "    fp16 = False\n",
    "    fp16_opt_level = '01'\n",
    "    server_ip = ''\n",
    "    server_port = ''\n",
    "    threads = 1\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hXQobtAY2G5_"
   },
   "outputs": [],
   "source": [
    "# Setup CUDA, GPU & distributed training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "args.n_gpu = torch.cuda.device_count()\n",
    "args.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "ZSFyqNZE2Ifw",
    "outputId": "58dd7331-8923-4ada-ef13-3fdf60b66d15"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/14/2020 19:11:02 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n"
     ]
    }
   ],
   "source": [
    " # Setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n",
    ")\n",
    "logger.warning(\n",
    "    \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
    "    args.local_rank,\n",
    "    device,\n",
    "    args.n_gpu,\n",
    "    bool(args.local_rank != -1),\n",
    "    args.fp16,\n",
    ")\n",
    "\n",
    "# Set seed\n",
    "set_seed(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 952
    },
    "colab_type": "code",
    "id": "b-GAZX9u2KvM",
    "outputId": "d3eef109-01e3-418f-cae7-42562bbc501d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/14/2020 19:11:20 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at C:\\Users\\lt\\.cache\\torch\\transformers\\b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "01/14/2020 19:11:20 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "01/14/2020 19:11:20 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at C:\\Users\\lt\\.cache\\torch\\transformers\\5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "01/14/2020 19:11:20 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at C:\\Users\\lt\\.cache\\torch\\transformers\\35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "01/14/2020 19:11:22 - INFO - transformers.modeling_utils -   Weights of BertForQuestionAnswering not initialized from pretrained model: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "01/14/2020 19:11:22 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "args.model_type = args.model_type.lower()\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
    "config = config_class.from_pretrained(\n",
    "    args.config_name if args.config_name else args.model_name_or_path,\n",
    "    cache_dir=args.cache_dir if args.cache_dir else None,\n",
    ")\n",
    "tokenizer = tokenizer_class.from_pretrained(\n",
    "    args.tokenizer_name if args.tokenizer_name else args.model_name_or_path,\n",
    "    do_lower_case=args.do_lower_case,\n",
    "    cache_dir=args.cache_dir if args.cache_dir else None,\n",
    ")\n",
    "model = model_class.from_pretrained(\n",
    "    args.model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
    "    config=config,\n",
    "    cache_dir=args.cache_dir if args.cache_dir else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "295c7ae5ccb3479db0a918ef46664718",
      "8308a18044d5487ea7c174375d34dc32",
      "d4efb28d50164ab19211ef7921fc2ee2",
      "546762858ab7438586799f88bb3b4c96",
      "3fd8298ddd344be8b22c516f2c781424",
      "1bb9d2b6123e41a6ad6cf17ba77a9902",
      "70381c5193734167b82dcf8627ea6a74",
      "d5519cd14d884dd3b7a49e794f445131",
      "40156f679b2f492ca15f2d8354ab5298",
      "bd8845d26f894b16a6240132d5e62632",
      "dd0705e24c764a1ca34b42f7a7b79201",
      "db56250357fd4f9caa4bb6d9763e4065",
      "99510af820634b419e0dabe01f1bf59f",
      "f387b3cbc14042bd9dbcc9925733918a",
      "c6275d3a872e4104913bb045afc3314f",
      "bbe299e2f0a74e59a052c1881f08909c"
     ]
    },
    "colab_type": "code",
    "id": "u2EMABVP2M7F",
    "outputId": "1f67fe9f-d9ea-4848-9619-766c7f0da54a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/14/2020 21:17:37 - INFO - __main__ -   Training/evaluation parameters <__main__.Args object at 0x7f2b799ab518>\n",
      "01/14/2020 21:17:37 - INFO - __main__ -   Loading features from cached file ./cached_train_bert-base-cased_384\n",
      "01/14/2020 21:18:03 - INFO - __main__ -   ***** Running training *****\n",
      "01/14/2020 21:18:03 - INFO - __main__ -     Num examples = 89632\n",
      "01/14/2020 21:18:03 - INFO - __main__ -     Num Epochs = 2\n",
      "01/14/2020 21:18:03 - INFO - __main__ -     Instantaneous batch size per GPU = 12\n",
      "01/14/2020 21:18:03 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 12\n",
      "01/14/2020 21:18:03 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "01/14/2020 21:18:03 - INFO - __main__ -     Total optimization steps = 14940\n",
      "\n",
      "\n",
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295c7ae5ccb3479db0a918ef46664718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=7470, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/14/2020 21:26:38 - INFO - transformers.configuration_utils -   Configuration saved in tmp/debug_squad/checkpoint-1000/config.json\n",
      "01/14/2020 21:26:39 - INFO - transformers.modeling_utils -   Model weights saved in tmp/debug_squad/checkpoint-1000/pytorch_model.bin\n",
      "01/14/2020 21:26:39 - INFO - __main__ -   Saving model checkpoint to tmp/debug_squad/checkpoint-1000\n",
      "01/14/2020 21:26:43 - INFO - __main__ -   Saving optimizer and scheduler states to tmp/debug_squad/checkpoint-1000\n",
      "01/14/2020 21:35:20 - INFO - transformers.configuration_utils -   Configuration saved in tmp/debug_squad/checkpoint-2000/config.json\n",
      "01/14/2020 21:35:21 - INFO - transformers.modeling_utils -   Model weights saved in tmp/debug_squad/checkpoint-2000/pytorch_model.bin\n",
      "01/14/2020 21:35:21 - INFO - __main__ -   Saving model checkpoint to tmp/debug_squad/checkpoint-2000\n",
      "01/14/2020 21:35:24 - INFO - __main__ -   Saving optimizer and scheduler states to tmp/debug_squad/checkpoint-2000\n",
      "01/14/2020 21:44:00 - INFO - transformers.configuration_utils -   Configuration saved in tmp/debug_squad/checkpoint-3000/config.json\n",
      "01/14/2020 21:44:01 - INFO - transformers.modeling_utils -   Model weights saved in tmp/debug_squad/checkpoint-3000/pytorch_model.bin\n",
      "01/14/2020 21:44:01 - INFO - __main__ -   Saving model checkpoint to tmp/debug_squad/checkpoint-3000\n",
      "01/14/2020 21:44:05 - INFO - __main__ -   Saving optimizer and scheduler states to tmp/debug_squad/checkpoint-3000\n",
      "01/14/2020 21:52:41 - INFO - transformers.configuration_utils -   Configuration saved in tmp/debug_squad/checkpoint-4000/config.json\n",
      "01/14/2020 21:52:42 - INFO - transformers.modeling_utils -   Model weights saved in tmp/debug_squad/checkpoint-4000/pytorch_model.bin\n",
      "01/14/2020 21:52:42 - INFO - __main__ -   Saving model checkpoint to tmp/debug_squad/checkpoint-4000\n",
      "01/14/2020 21:52:46 - INFO - __main__ -   Saving optimizer and scheduler states to tmp/debug_squad/checkpoint-4000\n",
      "01/14/2020 22:01:23 - INFO - transformers.configuration_utils -   Configuration saved in tmp/debug_squad/checkpoint-5000/config.json\n",
      "01/14/2020 22:01:24 - INFO - transformers.modeling_utils -   Model weights saved in tmp/debug_squad/checkpoint-5000/pytorch_model.bin\n",
      "01/14/2020 22:01:24 - INFO - __main__ -   Saving model checkpoint to tmp/debug_squad/checkpoint-5000\n",
      "01/14/2020 22:01:27 - INFO - __main__ -   Saving optimizer and scheduler states to tmp/debug_squad/checkpoint-5000\n",
      "01/14/2020 22:10:04 - INFO - transformers.configuration_utils -   Configuration saved in tmp/debug_squad/checkpoint-6000/config.json\n",
      "01/14/2020 22:10:05 - INFO - transformers.modeling_utils -   Model weights saved in tmp/debug_squad/checkpoint-6000/pytorch_model.bin\n",
      "01/14/2020 22:10:05 - INFO - __main__ -   Saving model checkpoint to tmp/debug_squad/checkpoint-6000\n",
      "01/14/2020 22:10:09 - INFO - __main__ -   Saving optimizer and scheduler states to tmp/debug_squad/checkpoint-6000\n",
      "01/14/2020 22:18:46 - INFO - transformers.configuration_utils -   Configuration saved in tmp/debug_squad/checkpoint-7000/config.json\n",
      "01/14/2020 22:18:47 - INFO - transformers.modeling_utils -   Model weights saved in tmp/debug_squad/checkpoint-7000/pytorch_model.bin\n",
      "01/14/2020 22:18:47 - INFO - __main__ -   Saving model checkpoint to tmp/debug_squad/checkpoint-7000\n",
      "01/14/2020 22:18:50 - INFO - __main__ -   Saving optimizer and scheduler states to tmp/debug_squad/checkpoint-7000\n",
      "\n",
      "\n",
      "Epoch:  50%|█████     | 1/2 [1:04:50<1:04:50, 3890.82s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40156f679b2f492ca15f2d8354ab5298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=7470, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/14/2020 22:27:27 - INFO - transformers.configuration_utils -   Configuration saved in tmp/debug_squad/checkpoint-8000/config.json\n",
      "01/14/2020 22:27:28 - INFO - transformers.modeling_utils -   Model weights saved in tmp/debug_squad/checkpoint-8000/pytorch_model.bin\n",
      "01/14/2020 22:27:28 - INFO - __main__ -   Saving model checkpoint to tmp/debug_squad/checkpoint-8000\n",
      "01/14/2020 22:27:32 - INFO - __main__ -   Saving optimizer and scheduler states to tmp/debug_squad/checkpoint-8000\n",
      "01/14/2020 22:36:08 - INFO - transformers.configuration_utils -   Configuration saved in tmp/debug_squad/checkpoint-9000/config.json\n",
      "01/14/2020 22:36:09 - INFO - transformers.modeling_utils -   Model weights saved in tmp/debug_squad/checkpoint-9000/pytorch_model.bin\n",
      "01/14/2020 22:36:09 - INFO - __main__ -   Saving model checkpoint to tmp/debug_squad/checkpoint-9000\n",
      "01/14/2020 22:36:12 - INFO - __main__ -   Saving optimizer and scheduler states to tmp/debug_squad/checkpoint-9000\n",
      "01/14/2020 22:44:49 - INFO - transformers.configuration_utils -   Configuration saved in tmp/debug_squad/checkpoint-10000/config.json\n",
      "01/14/2020 22:44:50 - INFO - transformers.modeling_utils -   Model weights saved in tmp/debug_squad/checkpoint-10000/pytorch_model.bin\n",
      "01/14/2020 22:44:50 - INFO - __main__ -   Saving model checkpoint to tmp/debug_squad/checkpoint-10000\n",
      "01/14/2020 22:44:54 - INFO - __main__ -   Saving optimizer and scheduler states to tmp/debug_squad/checkpoint-10000\n",
      "01/14/2020 22:53:31 - INFO - transformers.configuration_utils -   Configuration saved in tmp/debug_squad/checkpoint-11000/config.json\n",
      "01/14/2020 22:53:32 - INFO - transformers.modeling_utils -   Model weights saved in tmp/debug_squad/checkpoint-11000/pytorch_model.bin\n",
      "01/14/2020 22:53:32 - INFO - __main__ -   Saving model checkpoint to tmp/debug_squad/checkpoint-11000\n",
      "01/14/2020 22:53:36 - INFO - __main__ -   Saving optimizer and scheduler states to tmp/debug_squad/checkpoint-11000\n",
      "01/14/2020 23:02:12 - INFO - transformers.configuration_utils -   Configuration saved in tmp/debug_squad/checkpoint-12000/config.json\n",
      "01/14/2020 23:02:13 - INFO - transformers.modeling_utils -   Model weights saved in tmp/debug_squad/checkpoint-12000/pytorch_model.bin\n",
      "01/14/2020 23:02:13 - INFO - __main__ -   Saving model checkpoint to tmp/debug_squad/checkpoint-12000\n",
      "01/14/2020 23:02:17 - INFO - __main__ -   Saving optimizer and scheduler states to tmp/debug_squad/checkpoint-12000\n",
      "01/14/2020 23:10:53 - INFO - transformers.configuration_utils -   Configuration saved in tmp/debug_squad/checkpoint-13000/config.json\n",
      "01/14/2020 23:10:55 - INFO - transformers.modeling_utils -   Model weights saved in tmp/debug_squad/checkpoint-13000/pytorch_model.bin\n",
      "01/14/2020 23:10:55 - INFO - __main__ -   Saving model checkpoint to tmp/debug_squad/checkpoint-13000\n",
      "01/14/2020 23:10:58 - INFO - __main__ -   Saving optimizer and scheduler states to tmp/debug_squad/checkpoint-13000\n",
      "01/14/2020 23:19:35 - INFO - transformers.configuration_utils -   Configuration saved in tmp/debug_squad/checkpoint-14000/config.json\n",
      "01/14/2020 23:19:36 - INFO - transformers.modeling_utils -   Model weights saved in tmp/debug_squad/checkpoint-14000/pytorch_model.bin\n",
      "01/14/2020 23:19:36 - INFO - __main__ -   Saving model checkpoint to tmp/debug_squad/checkpoint-14000\n",
      "01/14/2020 23:19:40 - INFO - __main__ -   Saving optimizer and scheduler states to tmp/debug_squad/checkpoint-14000\n",
      "\n",
      "\n",
      "Epoch: 100%|██████████| 2/2 [2:09:42<00:00, 3891.00s/it]  \u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A01/14/2020 23:27:45 - INFO - __main__ -    global_step = 14941, average loss = 0.9776820335396322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(args.device)\n",
    "\n",
    "logger.info(\"Training/evaluation parameters %s\", args)\n",
    "\n",
    "# Training\n",
    "if args.do_train:\n",
    "    train_dataset = load_and_cache_examples(args, tokenizer, evaluate=False, output_examples=False)\n",
    "    global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n",
    "    logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 822
    },
    "colab_type": "code",
    "id": "a_cnUPRf2S34",
    "outputId": "f13aebf9-a375-4d29-e88c-25c308b2df58"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/14/2020 23:27:52 - INFO - __main__ -   Saving model checkpoint to tmp/debug_squad/\n",
      "01/14/2020 23:27:52 - INFO - transformers.configuration_utils -   Configuration saved in tmp/debug_squad/config.json\n",
      "01/14/2020 23:27:53 - INFO - transformers.modeling_utils -   Model weights saved in tmp/debug_squad/pytorch_model.bin\n",
      "01/14/2020 23:27:53 - INFO - transformers.configuration_utils -   loading configuration file tmp/debug_squad/config.json\n",
      "01/14/2020 23:27:53 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "01/14/2020 23:27:53 - INFO - transformers.modeling_utils -   loading weights file tmp/debug_squad/pytorch_model.bin\n",
      "01/14/2020 23:27:56 - INFO - transformers.tokenization_utils -   Model name 'tmp/debug_squad/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1). Assuming 'tmp/debug_squad/' is a path or url to a directory containing tokenizer files.\n",
      "01/14/2020 23:27:56 - INFO - transformers.tokenization_utils -   loading file tmp/debug_squad/vocab.txt\n",
      "01/14/2020 23:27:56 - INFO - transformers.tokenization_utils -   loading file tmp/debug_squad/added_tokens.json\n",
      "01/14/2020 23:27:56 - INFO - transformers.tokenization_utils -   loading file tmp/debug_squad/special_tokens_map.json\n",
      "01/14/2020 23:27:56 - INFO - transformers.tokenization_utils -   loading file tmp/debug_squad/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model and the tokenizer\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n",
    "    os.makedirs(args.output_dir)\n",
    "\n",
    "logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "# Take care of distributed/parallel training\n",
    "model_to_save = model.module if hasattr(model, \"module\") else model\n",
    "model_to_save.save_pretrained(args.output_dir)\n",
    "tokenizer.save_pretrained(args.output_dir)\n",
    "\n",
    "# Good practice: save your training arguments together with the trained model\n",
    "torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
    "\n",
    "# Load a trained model and vocabulary that you have fine-tuned\n",
    "model = model_class.from_pretrained(args.output_dir)  # , force_download=True)\n",
    "tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n",
    "model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 910,
     "referenced_widgets": [
      "b58fd82446a143c18f2ef954693b80ef",
      "014acd80b7ab4a6d8c2d375eb7615972",
      "fdc62dfb7ece40649976fb3e4acaa12b",
      "8275eb400e7543cebce9dbc031b66e81",
      "877bb321aa8a466491b072f05691abe7",
      "2e2b2c724f5a4afa93bb7fbfb623eca2",
      "690b2c84c6d0429caddfa9ba8e5eed23",
      "4efeb67541e24d3db5f2bfc31e5e4033"
     ]
    },
    "colab_type": "code",
    "id": "OjdGxMZ06kem",
    "outputId": "c176a9d5-7a1c-4d77-b4aa-a64045ecd528"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/14/2020 19:12:08 - INFO - __main__ -   Loading checkpoints saved during training for evaluation\n",
      "01/14/2020 19:12:08 - INFO - __main__ -   Evaluate the following checkpoints: tmp/debug_squad/\n",
      "01/14/2020 19:12:08 - INFO - transformers.configuration_utils -   loading configuration file tmp/debug_squad/config.json\n",
      "01/14/2020 19:12:08 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "01/14/2020 19:12:08 - INFO - transformers.modeling_utils -   loading weights file tmp/debug_squad/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation - we can ask to evaluate all the checkpoints (sub-directories) in a directory\n",
    "results = {}\n",
    "\n",
    "logger.info(\"Loading checkpoints saved during training for evaluation\")\n",
    "checkpoint = args.output_dir\n",
    "\n",
    "logger.info(\"Evaluate the following checkpoints: %s\", checkpoint)\n",
    "\n",
    "# Reload the model\n",
    "model = model_class.from_pretrained(checkpoint)  # , force_download=True)\n",
    "model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4eqnk2Xybyzy"
   },
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "result = evaluate(args, model, tokenizer)\n",
    "\n",
    "result = dict((k + (\"_{}\".format(global_step) if global_step else \"\"), v) for k, v in result.items())\n",
    "results.update(result)\n",
    "\n",
    "logger.info(\"Results: {}\".format(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bdOISimCeLga"
   },
   "outputs": [],
   "source": [
    "def predict(args,tokenizer,model,q,doc,device):\n",
    "    indexed_tokens = tokenizer.encode(q,doc)\n",
    "    seg_idx = indexed_tokens.index(102)+1\n",
    "    attention_mask = [1]*len(indexed_tokens)\n",
    "    segment_ids = [0]*seg_idx+[1]*(len(indexed_tokens)-seg_idx)\n",
    "    indexed_tokens += [0]*(args.max_seq_length-len(indexed_tokens))\n",
    "    attention_mask += [0]*(args.max_seq_length-len(attention_mask))\n",
    "    segment_ids += [0]*(args.max_seq_length-len(segment_ids))\n",
    "    \n",
    "    # for debugging\n",
    "    # ind2word = {v:k for k,v in tokenizer.vocab.items()}\n",
    "    # [ind2word[ind] for ind in indexed_tokens]\n",
    "\n",
    "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "    segment_tensor = torch.tensor([segment_ids]).to(device)\n",
    "    attention_tensor = torch.tensor([attention_mask]).to(device)\n",
    "\n",
    "    # Predict the start and end positions logits\n",
    "    with torch.no_grad():\n",
    "        start_logits, end_logits = model(tokens_tensor, token_type_ids=segment_tensor, attention_mask=attention_tensor)\n",
    "\n",
    "    # get the highest prediction\n",
    "    answer = tokenizer.decode(indexed_tokens[torch.argmax(start_logits):torch.argmax(end_logits)+1])\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bdOISimCeLga"
   },
   "outputs": [],
   "source": [
    "# The format is question first and then paragraph\n",
    "q = \"Who was Jim Henson?\"\n",
    "doc = \"Jim Henson was a puppeteer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'What did the pigs do for the rest of the day?'\n",
    "\n",
    "doc = \"Once upon a time there was an old mother pig who had three little pigs and not enough food to feed them. So when they were old enough, she sent them out into the world to seek their fortunes. The first little pig was very lazy. He didn't want to work at all and he built his house out of straw. The second little pig worked a little bit harder but he was somewhat lazy too and he built his house out of sticks. Then, they sang and danced and played together the rest of the day. The third little pig worked hard all day and built his house with bricks. It was a sturdy house complete with a fine fireplace and chimney. It looked like it could withstand the strongest winds. The next day, a wolf happened to pass by the lane where the three little pigs lived; and he saw the straw house, and he smelled the pig inside. He thought the pig would make a mighty fine meal and his mouth began to water.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bdOISimCeLga"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sang and danced and played together'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(args,tokenizer,model,q,doc,device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT-squad.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "014acd80b7ab4a6d8c2d375eb7615972": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bb9d2b6123e41a6ad6cf17ba77a9902": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "295c7ae5ccb3479db0a918ef46664718": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d4efb28d50164ab19211ef7921fc2ee2",
       "IPY_MODEL_546762858ab7438586799f88bb3b4c96"
      ],
      "layout": "IPY_MODEL_8308a18044d5487ea7c174375d34dc32"
     }
    },
    "2e2b2c724f5a4afa93bb7fbfb623eca2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fd8298ddd344be8b22c516f2c781424": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "40156f679b2f492ca15f2d8354ab5298": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dd0705e24c764a1ca34b42f7a7b79201",
       "IPY_MODEL_db56250357fd4f9caa4bb6d9763e4065"
      ],
      "layout": "IPY_MODEL_bd8845d26f894b16a6240132d5e62632"
     }
    },
    "4efeb67541e24d3db5f2bfc31e5e4033": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "546762858ab7438586799f88bb3b4c96": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5519cd14d884dd3b7a49e794f445131",
      "placeholder": "​",
      "style": "IPY_MODEL_70381c5193734167b82dcf8627ea6a74",
      "value": "100% 7470/7470 [1:04:50&lt;00:00,  2.34it/s]"
     }
    },
    "690b2c84c6d0429caddfa9ba8e5eed23": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "70381c5193734167b82dcf8627ea6a74": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8275eb400e7543cebce9dbc031b66e81": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4efeb67541e24d3db5f2bfc31e5e4033",
      "placeholder": "​",
      "style": "IPY_MODEL_690b2c84c6d0429caddfa9ba8e5eed23",
      "value": "100% 1372/1372 [02:42&lt;00:00,  8.43it/s]"
     }
    },
    "8308a18044d5487ea7c174375d34dc32": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "877bb321aa8a466491b072f05691abe7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "99510af820634b419e0dabe01f1bf59f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b58fd82446a143c18f2ef954693b80ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fdc62dfb7ece40649976fb3e4acaa12b",
       "IPY_MODEL_8275eb400e7543cebce9dbc031b66e81"
      ],
      "layout": "IPY_MODEL_014acd80b7ab4a6d8c2d375eb7615972"
     }
    },
    "bbe299e2f0a74e59a052c1881f08909c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd8845d26f894b16a6240132d5e62632": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6275d3a872e4104913bb045afc3314f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d4efb28d50164ab19211ef7921fc2ee2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Iteration",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1bb9d2b6123e41a6ad6cf17ba77a9902",
      "max": 7470,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3fd8298ddd344be8b22c516f2c781424",
      "value": 7470
     }
    },
    "d5519cd14d884dd3b7a49e794f445131": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db56250357fd4f9caa4bb6d9763e4065": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbe299e2f0a74e59a052c1881f08909c",
      "placeholder": "​",
      "style": "IPY_MODEL_c6275d3a872e4104913bb045afc3314f",
      "value": "100% 7470/7470 [1:04:51&lt;00:00,  2.35it/s]"
     }
    },
    "dd0705e24c764a1ca34b42f7a7b79201": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Iteration",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f387b3cbc14042bd9dbcc9925733918a",
      "max": 7470,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_99510af820634b419e0dabe01f1bf59f",
      "value": 7470
     }
    },
    "f387b3cbc14042bd9dbcc9925733918a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdc62dfb7ece40649976fb3e4acaa12b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Evaluating",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e2b2c724f5a4afa93bb7fbfb623eca2",
      "max": 1372,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_877bb321aa8a466491b072f05691abe7",
      "value": 1372
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
